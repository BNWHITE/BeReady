<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>R√©vision Probabilit√©s ISEP A1 - Dynamique</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header class="navbar">
        <div class="logo">EC **EARTHY COLOR** | <span class="sub-logo">Probabilit√©s A1</span></div>
        <nav>
            <a href="#probas-overview" class="nav-item">Th√©orie</a>
            <a href="#exercises-bank" class="nav-item">Exercices</a>
            <a href="#revision-plan" class="nav-item">Programme</a>
            <a href="#telecom" class="nav-item disabled">T√©l√©com (√Ä venir)</a>
        </nav>
        <button class="login-btn animate-pulse">Espace √âtudiant</button>
    </header>

    <main class="hero-section">
        <div class="hero-content">
            <h1 class="fade-in">See what's in it for you: R√©vision Probas ISEP</h1>
            <p class="fade-in delay-100">Pr√©parez efficacement vos examens de Probabilit√©s et T√©l√©communications pour le 29 Novembre 2025.</p>
            <div class="cta-group fade-in delay-200">
                <a href="#probas-overview" class="btn primary-btn pulse-effect">D√©marrer la Th√©orie üß†</a>
                <a href="#exercises-bank" class="btn secondary-btn">S'entrainer maintenant üìù</a>
            </div>
        </div>
        <div class="hero-image zoom-in">
            [Image of a student pointing to a concept map for probability]
        </div>
    </main>
    
    <div class="hr-separator"></div>

    <section id="probas-overview" class="content-blocks container">
        <h2 class="title-header">üìö Fiches de Th√©orie : Les Fondamentaux</h2>
        <p class="section-description">Naviguez √† travers les chapitres du cours ISEP A1 pour ma√Ætriser chaque notion. Cliquez pour voir les fiches d√©taill√©es.</p>
        <div class="cards-container">
            <a href="#chapitre-1-2" class="card creative-ideas">
                <h3>Ch. 1 & 2: Base & Ind√©pendance</h3>
                <p>Axiomes, Prob. conditionnelles, Formule des probabilit√©s totales, Bayes. üßê</p>
            </a>
            <a href="#chapitre-3-discret" class="card market-research">
                <h3>Ch. 3.1: VAR Discr√®tes (NP)</h3>
                <p>Bernoulli, **Binomiale $\mathcal{B}(n,p)$**, **Poisson $\mathcal{P}(\lambda)$**. Pourquoi et Quand les utiliser. üî¢</p>
            </a>
            <a href="#chapitre-3-continu" class="card best-solutions">
                <h3>Ch. 3.2: VAR Continues (GUVE)</h3>
                <p>**Gaussienne $\mathcal{N}(\mu, \sigma^2)$**, Uniforme, Exponentielle. Densit√©s. üìà</p>
            </a>
            <a href="#chapitre-6-7" class="card exercices-section">
                <h3>Ch. 6 & 7: Couple & Gaussien</h3>
                <p>Lois Jointes/Marginales, Covariance, Vecteurs Gaussiens. üåê</p>
            </a>
        </div>
    </section>

    <div class="hr-separator"></div>

    <section id="chapitre-3-discret" class="detailed-content container">
        <h2 class="title-header">üìù Chapitre 3.1 : Les Lois Discr√®tes Fondamentales</h2>
        <article class="topic-card">
            <h3 class="topic-title">Loi de Poisson $\mathcal{P}(\lambda)$ : Le Compte des √âv√©nements Rares</h3>
            <div class="topic-body">
                <p>**R√®gle d'Or (Pourquoi ?)** : On utilise la loi de Poisson pour mod√©liser le **nombre de r√©alisations d'√©v√©nements rares** (succ√®s) dans un intervalle de temps ou d'espace donn√©, √† condition que ces √©v√©nements soient ind√©pendants.</p>
                <p>**Formules Cl√©s** :
                    $$P[X=k]=e^{-\lambda}\frac{\lambda^{k}}{k!}$$
                    $$E(X)=\lambda$$
                    $$V(X)=\lambda$$
                </p>
                <p>**Cas d'Usage ISEP** : L'exercice 5 de l'Examen 2018 utilise la loi de Poisson pour mod√©liser le nombre de v√©hicules. La somme de deux lois de Poisson ind√©pendantes, $Z=X+Y$, suit une loi de Poisson de param√®tre $\lambda+\mu$.</p>
                </div>
        </article>
        
        <article class="topic-card">
            <h3 class="topic-title">Loi Binomiale $\mathcal{B}(n,p)$ : Les R√©p√©titions Ind√©pendantes</h3>
            <div class="topic-body">
                <p>**R√®gle d'Or (Pourquoi ?)** : Elle compte le nombre de **succ√®s $k$** obtenus sur un nombre fixe **$n$ d'√©preuves de Bernoulli ind√©pendantes**, o√π la probabilit√© de succ√®s est $p$.</p>
                <p>**Formules Cl√©s** :
                    $$P[X=k]=C_{n}^{k}p^{k}(1-p)^{n-k}$$
                    $$E(X)=np$$
                    $$V(X)=np(1-p)$$
                </p>
                <p>**Lien avec Poisson :** Si $n$ est grand et $p$ petit, la loi binomiale est approxim√©e par la loi de Poisson $\mathcal{P}(\lambda=np)$.</p>
                <p>**Cas d'Usage ISEP :** Dans l'exercice 3 de l'Examen 2022, la probabilit√© conditionnelle $P(Y=k \mid X=n)$ (le nombre de personnes choisissant le guichet 1 sachant qu'il y a $n$ personnes au total) suit une **loi binomiale $\mathcal{B}(n, p)$**.</p>
                </div>
        </article>
        </section>

    <div class="hr-separator"></div>

    <section id="exercises-bank" class="full-width-section container">
        <h2 class="title-header">üìù Banque d'Exercices et Probl√®mes ISEP A1</h2>
        <p class="section-description">Testez votre compr√©hension avec des exercices tir√©s des examens et TD ISEP. Pratiquez et v√©rifiez instantan√©ment vos r√©sultats.</p>
        
        <div class="exercise-category">
            <h3>I. Fondamentaux et Probabilit√©s Conditionnelles (Ch. 1-2)</h3>
            <article class="exercise-item">
                <h4>TD1-4: Le Filtrage T√©l√©phonique (Probas Totales & Bayes)</h4>
                <p>Gontran filtre les appels (60% externes $E$, 40% internes $\overline{E}$). Il refuse 80% des externes ($R|E$) et 30% des internes ($R|\overline{E}$).</p>
                <ol>
                    <li>Calculer $P(R)$, la probabilit√© qu'un appel soit refus√©.</li>
                    <li>Calculer $P(E|R)$, la probabilit√© qu'un appel refus√© provienne de l'ext√©rieur.</li>
                </ol>
                <button class="toggle-correction btn secondary-btn" data-target="corr-td1-4">Afficher la Correction</button>
                <div id="corr-td1-4" class="correction-box">
                    <p>1. **$P(R)$ (Formule des Probas Totales)** :
                        $$P(R) = P(R|E)P(E) + P(R|\overline{E})P(\overline{E})$$
                        $$P(R) = (0.80 \times 0.60) + (0.30 \times 0.40) = 0.48 + 0.12 = \mathbf{0.6}$$
                    </p>
                    <p>2. **$P(E|R)$ (Formule de Bayes)** :
                        $$P(E|R) = \frac{P(E \cap R)}{P(R)} = \frac{P(R|E)P(E)}{P(R)}$$
                        $$P(E|R) = \frac{0.48}{0.6} = \mathbf{0.8}$$
                        La probabilit√© qu'un appel refus√© soit externe est de 80%.
                    </p>
                </div>
            </article>

            </div>

        <div class="exercise-category">
            <h3>II. Probl√®mes de Lois Normales et Gaussiennes (Ch. 3.2, 6, 7)</h3>
            <article class="exercise-item">
                <h4>Examen 2018 - Exercice 2 (Admissibilit√© ISEP)</h4>
                <p>Les notes $X \sim \mathcal{N}(32.8; 8.5^2)$. Non-admissibles: $30\%$. Grands admissibles: $10\%$.</p>
                <p>D√©terminer l'intervalle de notes $[N_{min}, N_{max}]$ pour passer l'oral (Admissibles simples).</p>
                <button class="toggle-correction btn secondary-btn" data-target="corr-exo2-2018">Afficher la Correction</button>
                <div id="corr-exo2-2018" class="correction-box">
                    <p>**Calcul du Seuil Non-Admissible ($N_{min}$)** : On cherche $n_{min}$ tel que $P(X < n_{min}) = 0.30$.</p>
                    <p>En Centrant et R√©duisant : $P(Z < z_{min}) = 0.30$. Par sym√©trie, $P(Z > -z_{min}) = 0.30$. Donc $P(0 < Z < -z_{min}) = 0.5 - 0.3 = 0.2$.</p>
                    <p>D'apr√®s la table de $\mathcal{N}(0,1)$, $G(0.52) \approx 0.1985$ et $G(0.53) \approx 0.2019$. Nous prenons $z_{min} \approx -0.525$.</p>
                    <p>$$n_{min} = \mu + z_{min} \sigma = 32.8 + (-0.525) \times 8.5 \approx 32.8 - 4.46 \approx \mathbf{28.34}$$</p>
                    <p>**Calcul du Seuil Grand Admissible ($N_{max}$)** : On cherche $n_{max}$ tel que $P(X \ge n_{max}) = 0.10$.</p>
                    <p>En Centrant et R√©duisant : $P(Z \ge z_{max}) = 0.10$. Donc $P(0 < Z < z_{max}) = 0.5 - 0.1 = 0.4$.</p>
                    <p>D'apr√®s la table, $G(1.28) \approx 0.3997$. Nous prenons $z_{max} \approx 1.28$.</p>
                    <p>$$n_{max} = \mu + z_{max} \sigma = 32.8 + (1.28) \times 8.5 \approx 32.8 + 10.88 \approx \mathbf{43.68}$$</p>
                    <p>L'intervalle de notes pour passer l'oral est $[\mathbf{28.34}, \mathbf{43.68}]$.</p>
                </div>
            </article>
            </div>

        <div class="exercise-category">
            <h3>III. Couples de VAR et Lois Discr√®tes (Ch. 3.1, 6, 7)</h3>
            <article class="exercise-item">
                <h4>Examen 2018 - Exercice 5 (Loi Conditionnelle Poisson)</h4>
                <p>Soient $X \sim \mathcal{P}(\lambda)$ (v√©hicules quittant Paris) et $Y \sim \mathcal{P}(\mu)$ (v√©hicules rentrant sur Paris) ind√©pendantes. $Z=X+Y$ est le nombre total de v√©hicules.</p>
                <p>Calculer la probabilit√© conditionnelle $P(X=k \mid Z=n)$, c'est-√†-dire la probabilit√© que $k$ v√©hicules quittent Paris sachant que $n$ v√©hicules ont franchi le p√©age.</p>
                <button class="toggle-correction btn secondary-btn" data-target="corr-exo5-2018">Afficher la Correction</button>
                <div id="corr-exo5-2018" class="correction-box">
                    <p>**D√©monstration** :
                        $$P(X=k \mid Z=n) = \frac{P(X=k \cap Z=n)}{P(Z=n)}$$
                        Sachant que $Z=X+Y$, l'√©v√©nement $\{X=k \cap Z=n\}$ est √©quivalent √† $\{X=k \cap Y=n-k\}$.</p>
                    <p>Puisque $X$ et $Y$ sont ind√©pendantes :
                        $$P(X=k \cap Y=n-k) = P(X=k)P(Y=n-k)$$
                        $$P(X=k \cap Y=n-k) = \left(e^{-\lambda}\frac{\lambda^k}{k!}\right) \left(e^{-\mu}\frac{\mu^{n-k}}{(n-k)!}\right) = e^{-(\lambda+\mu)} \frac{\lambda^k \mu^{n-k}}{k! (n-k)!}$$
                    </p>
                    <p>D'autre part, $Z=X+Y \sim \mathcal{P}(\lambda+\mu)$ :
                        $$P(Z=n) = e^{-(\lambda+\mu)}\frac{(\lambda+\mu)^n}{n!}$$
                    </p>
                    <p>En rempla√ßant :
                        $$P(X=k \mid Z=n) = \frac{e^{-(\lambda+\mu)} \frac{\lambda^k \mu^{n-k}}{k! (n-k)!}}{e^{-(\lambda+\mu)}\frac{(\lambda+\mu)^n}{n!}} = \frac{n!}{k! (n-k)!} \frac{\lambda^k \mu^{n-k}}{(\lambda+\mu)^n}$$
                    </p>
                    <p>Finalement, en factorisant $(\lambda+\mu)^n = (\lambda+\mu)^k (\lambda+\mu)^{n-k}$ :
                        $$P(X=k \mid Z=n) = C_n^k \left(\frac{\lambda}{\lambda+\mu}\right)^k \left(\frac{\mu}{\lambda+\mu}\right)^{n-k}$$
                    </p>
                    <p>**Conclusion (Bonus)** : On reconna√Æt la loi de probabilit√© Binomiale $\mathcal{B}(n, p)$, avec :
                        $$p = \frac{\lambda}{\lambda+\mu}$$
                        La probabilit√© d'avoir $k$ v√©hicules quittant Paris, sachant que le total est $n$, suit une Loi Binomiale.
                    </p>
                </div>
            </article>

            </div>

    </section>

    <div class="hr-separator"></div>

    <section id="revision-plan" class="content-blocks container">
        <h2 class="title-header">üóìÔ∏è Votre Programme de R√©vision (29 NOVEMBRE 2025)</h2>
        </section>

    <footer>
        <p>¬© 2025 ISEP A1 - Probabilit√©s & T√©l√©communications. Tous droits r√©serv√©s.</p>
    </footer>

    <script src="script.js"></script>
</body>
</html>
